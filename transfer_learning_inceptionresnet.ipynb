{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in Tensorflow with Pre-trained Inception-Resnet Model from TF-Slim\n",
    "\n",
    "In this project, we are going to use a pre-trained inception-resnet model fromTensorflow Slim (TF-Slim)\n",
    "to classify images from another dataset. TF-Slim is a wrapper for tensorflow that makes it particularly easy to use pre-trained models for image classification,\n",
    "amongst other things.\n",
    "<br>\n",
    "<br> You can check out the official documentation of TF-Slim here (this tutorial is adapted from the documentation): https://github.com/tensorflow/models/blob/master/slim/README.md\n",
    "<br>As well as a slim walk-through with examples: https://github.com/tensorflow/models/blob/master/slim/slim_walkthrough.ipynb\n",
    "\n",
    "<br>One modification to adapt a pre-trained model to your use case, is to remove the final pre-softmax layer and to replace it\n",
    "with weights/logits that correspond to the number of classes/labels in your (smaller) dataset. We then tune the model on this new dataset.\n",
    "\n",
    "<br>Before you write any code, be sure to install TF-Slim and the corresponding image models library.\n",
    "The instructions are found in the official documentation: https://github.com/tensorflow/models/blob/master/slim/README.md\n",
    "<br><br>Note, first install the models library and then place slim in this models directory.\n",
    "<br>I found the following resource clearer than the documentation for figuring out how to create and structure the directories:\n",
    "https://hackaday.io/project/20448-elephant-ai/log/56896-retraining-tensorflow-inception-v3-using-tensorflow-slim-part-1\n",
    "\n",
    "<br>I also assume you've converted your data into TFRecord format, see my other post on how to do that.\n",
    "\n",
    "<br> Okay! Now we can code!\n",
    "First, let us import all the things we will need.\n",
    "\n",
    "Note that the imports \"inception_resnet_v2\" and \"inception_preprocessing\" come from the TF-Slim models library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import inception_resnet_v2  #From: https://github.com/tensorflow/models/blob/master/slim/nets/inception_resnet_v2.py\n",
    "import inception_preprocessing # From: https://github.com/tensorflow/models/blob/master/slim/preprocessing/inception_preprocessing.py\n",
    "from tensorflow.contrib import slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate Directories\n",
    "\n",
    "The next step is to locate the relevant directories (incl. checkpoint), and to provide some information about your dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset directory where the tfrecord files are located\n",
    "dataset_dir = \"/Users/charujaiswal/PycharmProjects/models/slim/DATASET/flowers\"\n",
    "# I created a directory within slim where I placed the converted tfrecord files. \n",
    "\n",
    "#State where your log file is. If it doesn't exist yet, it will be created below in a function.\n",
    "log_dir = './log'\n",
    "\n",
    "#Location of checkpoint file (see hackaday.io as mentioned aboved for how to structure directory)\n",
    "checkpoint_file = \"/Users/charujaiswal/PycharmProjects/models/slim/CHECKPOINTDIR/inception_resnet_v2_2016_08_30.ckpt\"\n",
    "\n",
    "#Locate the labels file and then read it\n",
    "labels_file = '/Users/charujaiswal/PycharmProjects/models/slim/DATASET/flowers/labels.txt'\n",
    "labels = open(labels_file, 'r')\n",
    "\n",
    "#The image size you're resizing your images to-- here we use the default inception size of 299.\n",
    "image_size = inception_resnet_v2.inception_resnet_v2.default_image_size # 299\n",
    "\n",
    "#Number of classes to predict:\n",
    "num_classes = 5 # the flowers dataset has 5 classes\n",
    "\n",
    "#Batch size \n",
    "batch_size= 10\n",
    "\n",
    "#Number of epochs \n",
    "num_epochs= 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slim's documentation has an informative file called \"learning.py\", located here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/learning.py\n",
    "\n",
    "<br> In it is a useful generalized overview of how to fine-tune a model from a checkpoint, we will loosely follow this process, I've reproduced it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train_op\n",
    "train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "checkpoint_path = '/path/to/old_model_checkpoint'\n",
    "# Specify the variables to restore via a list of inclusion or exclusion\n",
    "# patterns:\n",
    "variables_to_restore = slim.get_variables_to_restore(\n",
    "  include=[\"conv\"], exclude=[\"fc8\", \"fc9])\n",
    "# or\n",
    "variables_to_restore = slim.get_variables_to_restore(exclude=[\"conv\"])\n",
    "init_assign_op, init_feed_dict = slim.assign_from_checkpoint(\n",
    "  checkpoint_path, variables_to_restore)\n",
    "# Create an initial assignment function.\n",
    "def InitAssignFn(sess):\n",
    "  sess.run(init_assign_op, init_feed_dict)\n",
    "# Run training.\n",
    "slim.learning.train(train_op, my_log_dir, init_fn=InitAssignFn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data with TF-Slim: Dataset and DatasetDataProvider \n",
    "Before we can write the train_op etc. we will need to figure out how to read the data. Reading data in TF-Slim has two parts: a Dataset (descriptor of dataset) and a DatasetDataProvider (actually reads the data). \n",
    "\n",
    "<br> We took care of the Dataset when we converted our data into TFRecord files. DatasetDataProvider is a class that reads the data, and can be configured to read the data in various ways-- including if your data is sharded.\n",
    "The first step in this process of feeding the data correctly is to get a dataset tuple with instructions for reading our data. We will write this into a function that is adapted from the function \"get_split\" that is in the file: models/slim/datasets/flowers.py. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### LOADING THE DATASET ##########\n",
    "\n",
    "# Here we create a function that creates a Dataset class which will give us TFRecord files to feed into a queue in parallel.\n",
    "def get_split(split_name, dataset_dir, file_pattern=file_pattern):\n",
    "\n",
    "    \"\"\"Gets a dataset tuple with instructions for reading the data.\n",
    "    Args:\n",
    "    split_name: A train/validation split name.\n",
    "    dataset_dir: The base directory of the dataset sources.\n",
    "    file_pattern: The file pattern to use when matching the dataset sources.\n",
    "      It is assumed that the pattern contains a '%s' string so that the split\n",
    "      name can be inserted.\n",
    "\n",
    "    Returns:\n",
    "    A `Dataset` namedtuple.\n",
    "    Raises:\n",
    "    ValueError: if `split_name` is not a valid train/validation split.\n",
    "    \"\"\"\n",
    "    # First check whether the split_name is train or validation\n",
    "    if split_name not in ['train', 'validation']:\n",
    "      raise ValueError('The split_name %s is not recognized.' % (split_name))\n",
    "\n",
    "    # Create a path to locate the tfrecord files, using file_pattern of the name\n",
    "    file_pattern_path = os.path.join(dataset_dir, file_pattern % (split_name))\n",
    "\n",
    "    # Create a reader that outputs the records from a tfrecord file\n",
    "    reader = tf.TFRecordReader\n",
    "\n",
    "    #Count the number of samples\n",
    "    num_samples = 0\n",
    "    file_pattern_for_counting = 'flowers_tfrecord' + split_name\n",
    "    tfrecords_to_count = [os.path.join(dataset_dir, file) for file in os.listdir(dataset_dir) if\n",
    "                          file.startswith(file_pattern_for_counting)]\n",
    "    for tfrecord_file in tfrecords_to_count:\n",
    "        for record in tf.python_io.tf_record_iterator(tfrecord_file):\n",
    "            num_samples += 1\n",
    "\n",
    "    ##Next we create the keys_to_features and item_to_handlers dictionaries and the decoder which are used later by the\n",
    "    # DatasetDataProvider object to decode tf-example into tensor objects.\n",
    "\n",
    "    ''' More detail on the DatasetDataProvider later\n",
    "    '''\n",
    "\n",
    "    # Create the keys_to_features dictionary for the decoder\n",
    "    keys_to_features = {\n",
    "        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpg'),\n",
    "        'image/class/label': tf.FixedLenFeature(\n",
    "            [], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "\n",
    "    # Create the items_to_handlers dictionary for the decoder.\n",
    "    items_to_handlers = {\n",
    "        'image': slim.tfexample_decoder.Image(),\n",
    "        'label': slim.tfexample_decoder.Tensor('image/class/label'),\n",
    "    }\n",
    "\n",
    "    # Start to create the decoder\n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "\n",
    "    # Create the labels_to_name file\n",
    "    labels_to_name_dict = labels_to_name\n",
    "\n",
    "    # Actually create the dataset\n",
    "    dataset = slim.dataset.Dataset(\n",
    "        data_sources=file_pattern_path,\n",
    "        decoder=decoder,\n",
    "        reader=reader,\n",
    "        num_readers=4,\n",
    "        num_samples=num_samples,\n",
    "        num_classes=num_classes,\n",
    "        labels_to_name=labels_to_name_dict,\n",
    "        items_to_descriptions=items_to_descriptions)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DatasetDataProvider and How to Load Data \n",
    "\n",
    "The next thing we will do is load tensors from out dataset into batches for training-- via the DatasetDataProvider object. We will create a function called \"load_batch\" that will 1) process our images to fit the format required by the inception network, 2) return the processed images as batches of tensors, 3) return the corresponding labels and 4) return the raw images in case you want to visualize them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size=batch_size, height=image_size, width=image_size, is_training=True):\n",
    "    \"\"\"Loads a single batch of data for training.\n",
    "\n",
    "    Args:\n",
    "      dataset: The dataset to load, created in the get_split function.\n",
    "      batch_size: The number of images in the batch.\n",
    "      height(int): int value that is the size the image will be resized to during preprocessing\n",
    "      width: The size that the image will be resized to during preprocessing\n",
    "      is_training: Whether or not we're currently training or evaluating.\n",
    "\n",
    "    Returns:\n",
    "      images: A Tensor of size [batch_size, height, width, channels(3)], image samples that have been preprocessed, that contain one batch of images.\n",
    "      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n",
    "      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes (requires one-hot encodings)\n",
    "    \"\"\"\n",
    "\n",
    "    # First create the data_provider object\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset,\n",
    "        common_queue_capacity=32,\n",
    "        common_queue_min=8)\n",
    "\n",
    "    # Obtain the raw image using the get method\n",
    "    raw_image, label = data_provider.get(['image', 'label'])\n",
    "\n",
    "    # Perform the correct preprocessing for this image depending if it is training or evaluating\n",
    "    image = inception_preprocessing.preprocess_image(raw_image, height, width, is_training)\n",
    "\n",
    "    # Preprocess the image for display purposes.\n",
    "    raw_image = tf.expand_dims(raw_image, 0)\n",
    "    raw_image = tf.image.resize_nearest_neighbor(raw_image, [height, width])\n",
    "    raw_image = tf.squeeze(raw_image)\n",
    "\n",
    "    # Batch up the images by enqueing the tensors internally in a FIFO queue and dequeueing many elements with tf.train.batch.\n",
    "    images, raw_images, labels = tf.train.batch(\n",
    "        [image, raw_image, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=4,\n",
    "        capacity=4 * batch_size,\n",
    "        allow_smaller_final_batch=True)\n",
    "\n",
    "    return images, raw_images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Graph \n",
    "\n",
    "<br> Now we will create a graph in a run function, and will also create a log directory that will be useful if you want to visualize the training in tensorboard. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Create the log directory here. When training, it's helpful to train and evaluate progress in real-time.\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "\n",
    "    # ======================= TRAINING =========================\n",
    "    # Construct the graph and build our model\n",
    "    with tf.Graph().as_default():\n",
    "        tf.logging.set_verbosity(tf.logging.INFO)  # Sets the threshold for what messages will be logged, in this case it is set to 'INFO'\n",
    "\n",
    "        # Get dataset and load a batch\n",
    "        dataset = get_split('train', dataset_dir, file_pattern=file_pattern)\n",
    "        images, _, labels = load_batch(dataset, batch_size=batch_size)\n",
    "\n",
    "\n",
    "        #Create the model, use the default arg scope to configure the batch norm parameters.\n",
    "        with slim.arg_scope(inception_resnet_v2.inception_resnet_v2_arg_scope()):\n",
    "            logits, end_points = inception_resnet_v2.inception_resnet_v2(images, num_classes=dataset.num_classes, is_training=True)\n",
    "\n",
    "        #Scopes that you want to exclude for restoration, from the checkpoint\n",
    "        exclude = ['InceptionResnetV2/Logits', 'InceptionResnetV2/AuxLogits']\n",
    "        variables_to_restore = slim.get_variables_to_restore(exclude=exclude)\n",
    "\n",
    "        #One-hot encode the labels\n",
    "        one_hot_labels = slim.one_hot_encoding(labels, dataset.num_classes)\n",
    "\n",
    "        #Specify the loss function;\n",
    "        # slim.losses.softmax_cross_entropy(logits, one_hot_labels)\n",
    "        # total_loss = slim.losses.get_total_loss()\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=logits)\n",
    "        total_loss = tf.losses.get_total_loss()  # obtain the regularization losses as well\n",
    "\n",
    "        # Specify the optimizer and create the train op:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "        train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "\n",
    "        # State the metrics that you want to predict.\n",
    "        predictions = tf.argmax(end_points['Predictions'], 1)\n",
    "        accuracy, accuracy_update = tf.contrib.metrics.streaming_accuracy(predictions, labels)\n",
    "\n",
    "        # Create some summaries to visualize the training process:\n",
    "        tf.summary.scalar('losses/Total_Loss', total_loss)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "\n",
    "        #Now we will restore the variables from the checkpoint file\n",
    "        init_fn = slim.assign_from_checkpoint_fn(checkpoint_file, slim.get_variables_to_restore())\n",
    "\n",
    "\n",
    "        # Run the training inside a session:\n",
    "\n",
    "        final_loss = slim.learning.train(\n",
    "            train_op,\n",
    "            logdir=log_dir,\n",
    "            init_fn=init_fn,\n",
    "            number_of_steps=num_epochs)\n",
    "\n",
    "\n",
    "    print('Finished training. Last batch loss %f' % final_loss)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Conveniently, the slim.learning.train function used above does the following:\n",
    "1) For each iteration, evaluates the train_op, which updates the parameters using the optimizer applied to the current minibatch. Also, updates the global_step.\n",
    "2) Occasionally store the model checkpoint in the specified directory. This is useful in case your machine crashes - then you can simply restart from the specified checkpoint.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}